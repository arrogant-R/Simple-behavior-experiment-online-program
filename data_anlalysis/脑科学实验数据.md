### 脑科学实验数据

* [info.csv](info.csv) 被试基本信息。**注意第九行(index9)开始是实验模式修改后的数据。**

* [train2014](train2014)：使用的100张图片。

* [detect](detect)：上述图片用yolov8检测出目标后的图片，子文件夹[labels](detect/labels)中的txt文件是对应图片中检测出目标的标签和位置(左上角。右下角)。具体地，标签`0`是person。

* [samples_reindex.json](samples_reindex.json) : keys的编号从1开始，实验展示图片的顺序按keys的编号。对应值包含着使用图片的名称和句子, 只用的句子是sentence中的第一个，即 \['编号'\]\['sentences'\]\[0\]\['translation'\]。

* [sent.csv](sent.csv) 被试在句子页面的点击continue的反应时。不同行不同被试，第i行对应着info.csv中第i个被试。不同列对应不同图片的描述句子，第j列代表第j个图片的sentence，具体是哪张图片请查阅samples_reindex.json，列的编号与samples_reindex.json的一致，从1开始。

* [xy.csv](xy.csv) 被试点击的图片的百分比位置. 文件格式同sent.csv, x,y的保存形式为字符串‘{x}_{y}'。"-1\_-1"表示点击不存在，0\_0表示没有完成点击跳过（实验修改前）。

* [t.csv](t.csv) 被试点击图片的反应时，100000.0表示被试没有完成点击自动跳过。

  

  
  
  #### 当第n张图片确定存在目标时，判断点击位置是否正确

  ```python
  ref = samples[str(n)]
  x,y=pd.read_csv('xy.csv')[which_subject,str(n)].split("_")
  x,y = float(x),float(y)
  
  def is_click_right(x, y, ref):
      """
      xy: 被试点击的相对坐标
      对应图片的json文件记录,ref = samples[str(n)]
      """
      image_dir = "train2014"
      file_name = ref['file_name']
      i = Image.open(os.path.join(image_dir, file_name))
      w = i.width
      h = i.height
  
      ann = ref['annotation']
      if type(ann['segmentation'][0]) == list: # polygon
          rle = mask.frPyObjects(ann['segmentation'], h, w)
      else:
          rle = ann['segmentation']
  
      m = mask.decode(rle)
      m = np.sum(m, axis=2)
  
      x = x*w
      y = y*h
  
      if m[int(y), int(x)] == 0:
          return False
  
      return True
  ```

  #### 判断对错

  ```python
  if (t > 10000) or (ref['ann_id'][0] == -1
  and x != -1) or (ref['ann_id'][0] != -1 and x == -1): 
  #三个括号分别代表 1.超时 2.不存在 却点击了图片 # 存在却点击不存在
  	right = False
  elif (ref['ann_id'][0] == -1 and x == -1):  # 图片不存在 点击 不存在
  	right = True
  else:  # 图片存在，用户也点击了
  	right = is_click_right(x, y, ref)
  print(f"correct? {right}")
  ```

  ### 可视化-高亮需要点击的区域
```python
import os
import skimage.io as io
import numpy as np
import matplotlib.pyplot as plt

from matplotlib.collections import PatchCollection
from matplotlib.patches import Polygon, Rectangle
from pycocotools import mask
from PIL import Image
import os
import json

samples = json.load(open("samples_reindex.json", 'r'))
samples.keys()

def show_ref(ref):
    image_dir = "train2014"
    image_name = ref['file_name']
    I = io.imread(os.path.join(image_dir, image_name))

    # ax = plt.gca()
    # ax.imshow(I)
    # plt.xticks([])
    # plt.yticks([])
    # #plt.show()

    ax = plt.gca()
    ax.imshow(I)

    print('%s' % (ref['sentences'][0]['sent']))

    ann_ids = ref['ann_id']
    for i, ann_id in enumerate(ann_ids):
        if ann_id == -1:
            continue
        # ann = ref['annotation'][i]
        ann = ref['annotation']

        polygons = []
        color = []
        c = 'none'

        # refcoco
        for seg in ann['segmentation']:
            poly = np.array(seg).reshape(((int(len(seg) / 2)), 2))
            polygons.append(Polygon(poly, True, alpha=0.4))
            color.append(c)
        p = PatchCollection(polygons, facecolors=(0,0,0,0), edgecolors=(1, 1, 0, 1), linewidths=2)
        ax.add_collection(p)  # thick yellow polygon
        p = PatchCollection(polygons, facecolors=(0,0,0,0), edgecolors=(1, 0, 0, 1), linewidths=1)
        ax.add_collection(p)  # thin red polygon
        
        mask_out(ref,ax)
        plt.xticks([])
        plt.yticks([])
        #plt.savefig(f'GT/{image_name}',bbox_inches = 'tight',pad_inches = 0)
        
        plt.show()
def mask_out(ref, ax):
    """
    ref: json文件中的.values()
    """
    image_dir = "train2014"
    file_name = ref['file_name']
    i = Image.open(os.path.join(image_dir, file_name))
    w = i.width
    h = i.height

    ann = ref['annotation']
    if type(ann['segmentation'][0]) == list:  # polygon
        rle = mask.frPyObjects(ann['segmentation'], h, w)
    else:
        rle = ann['segmentation']

    m = mask.decode(rle)
    m = np.sum(m, axis=2)

    rgba_image = np.zeros((*m.shape, 4))
    rgba_image[m == 0] = [0, 0, 0, 1]
    rgba_image[m > 0] = [0, 0, 0, 0]

    # mask according to the segmentation
    ax.imshow(rgba_image, alpha=0.5)
for iid in samples.keys():
    ref = samples[iid]
    show_ref(ref)
    input('回车继续')
    
```
  